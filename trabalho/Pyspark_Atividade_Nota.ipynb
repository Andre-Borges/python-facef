{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Uni-Facef - Pyspark - Atividade Nota.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXkZ_dWqImMI"
      },
      "source": [
        "# <font color='blue'>Uni-Facef - Pyspark - Atividade</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxfv0d4NImMJ"
      },
      "source": [
        "**Trabalho Python Facef - André Borges [22290**]\n",
        "\n",
        "Essa atividade tem como objetivo descobrir um pouco mais sobre o cliente e traçar um perfil do mesmo. Visto que temos as informações pessoais do cliemte em um arquivo chamado \"cliente_fake.csv\", e os dados transacionais desse cliente no arquivo chamado \"venda_fake\". E idéia do exercicio é a manipulação dos dados de forma a fazer agregações, join nos dados, podendo ser necessário o uso de UDFs, gerando um Dataframe Final:\n",
        "\n",
        "#### O Dataframe final deve estar agrupado por cliente (cliente_id), e conter as seguintes informações:\n",
        "\n",
        "- cliente_id - O identificador do cliente\n",
        "- idade - Calcular a idade do cliente (valor inteiro)\n",
        "- recencia - Calcular a quantos meses faz que o cliente não compra (valor inteiro)\n",
        "- qt_total_compras - Quantidade total de compras (pedidos distintos)\n",
        "- vr_total_compras = Valor total de compras do cliente\n",
        "- qt_total_itens - Quantidade total de itens comprados pelo cliente (produto_id distintos)\n",
        "- qt_max_parcelas - Quantidade máxima de parcelas que o cliente já utilizou\n",
        "- perfil_cliente - Deve mostrar o perfil de compra desse cliente, se compra somente \"loja\" ou somente \"online\", ou em ambos \"multicanal\";\n",
        "\n",
        "OBS: O dataset \"venda_fake\" está a nível de itens. Pode haver mais de um item por pedido, ito é, o numero do pedido pode estar duplicado nodataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SFqfbCJJVLv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhjiF4bOImMK",
        "outputId": "07ecb429-3e85-46c6-8d0f-79af7c8af8b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2MB 63kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 44.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612243 sha256=031fa46310093005244ad85991eede8ef6cf23e02559ef0fc1ed11fb0794cc91\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTJLHncjImMN"
      },
      "source": [
        "# coding: utf-8\n",
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F-fZ4WGImMQ"
      },
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName('ConhecendoCliente') \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nzmH0BeImMS"
      },
      "source": [
        "#### Dataset de cliente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyvWUFoCImMT",
        "outputId": "447dc7cc-2ea5-49dd-86a0-6413fea0428d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_cliente = spark.read \\\n",
        "    .option(\"delimiter\", \"|\") \\\n",
        "    .csv('cliente_fake.csv', header=True)\n",
        "\n",
        "df_cliente.orderBy('cliente_id').show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+----------+-------------+\n",
            "|          nome|cliente_id|dt_nascimento|\n",
            "+--------------+----------+-------------+\n",
            "|Cliente 100001|    100001|   2009-04-16|\n",
            "|Cliente 100002|    100002|   1974-08-29|\n",
            "|Cliente 100003|    100003|   1981-12-05|\n",
            "|Cliente 100004|    100004|   1968-08-08|\n",
            "|Cliente 100005|    100005|   1982-11-29|\n",
            "|Cliente 100006|    100006|   1948-04-01|\n",
            "|Cliente 100007|    100007|   1976-11-04|\n",
            "|Cliente 100008|    100008|   1980-12-01|\n",
            "|Cliente 100009|    100009|   1981-03-05|\n",
            "|Cliente 100010|    100010|   1984-03-20|\n",
            "|Cliente 100011|    100011|   1977-11-22|\n",
            "|Cliente 100012|    100012|   1974-02-04|\n",
            "|Cliente 100013|    100013|   1964-06-21|\n",
            "|Cliente 100014|    100014|   1964-05-24|\n",
            "|Cliente 100015|    100015|   1946-10-18|\n",
            "|Cliente 100016|    100016|   1972-03-24|\n",
            "|Cliente 100017|    100017|   1982-01-19|\n",
            "|Cliente 100018|    100018|   1983-04-26|\n",
            "|Cliente 100019|    100019|   1971-09-09|\n",
            "|Cliente 100020|    100020|   1989-06-18|\n",
            "+--------------+----------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T3AMYjBImMW"
      },
      "source": [
        "#### Dataset de pedido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygCRdopUImMW",
        "outputId": "cc1c568a-6af5-4377-f2a7-42058731c531",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_venda = spark.read \\\n",
        "    .option(\"delimiter\", \"|\") \\\n",
        "    .csv('venda_fake.csv', header=True)\n",
        "\n",
        "df_venda.orderBy('cliente_id').show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+----------+--------------------+----------+-----------+--------------+------------+-------+--------+\n",
            "|     pedido_id|cliente_id|           dt_pedido|produto_id|qt_parcelas|   forma_pagto|vr_unit_item|qt_item|tp_canal|\n",
            "+--------------+----------+--------------------+----------+-----------+--------------+------------+-------+--------+\n",
            "|10000120200626|    100001|2020-06-26T00:00:...|   7560984|         16|cartao credito|     1399.04|      1|    loja|\n",
            "|10000220200221|    100002|2020-02-21T00:00:...|   7637880|          9|         carne|     1280.07|      1|    loja|\n",
            "|10000320200730|    100003|2020-07-30T00:00:...|   7642944|         10|        outros|      998.96|      1|    loja|\n",
            "|10000320200810|    100003|2020-08-10T00:00:...|   7642956|          9|        outros|         899|      1|    loja|\n",
            "|10000320200810|    100003|2020-08-10T00:00:...|   6906072|          9|        outros|        6.99|      1|    loja|\n",
            "|10000420200109|    100004|2020-01-09T00:00:...|   7213236|         20|cartao credito|        2294|      1|    loja|\n",
            "|10000420200107|    100004|2020-01-07T00:00:...|   6879168|         24|cartao credito|   2272.0801|      1|    site|\n",
            "|10000420200109|    100004|2020-01-09T00:00:...|   7213236|          1|        debito|        2294|      1|    loja|\n",
            "|10000520200214|    100005|2020-02-14T00:00:...|   7589448|         13|         carne|     1242.28|      1|    loja|\n",
            "|10000520200121|    100005|2020-01-21T00:00:...|   7197636|         15|         carne|        1965|      1|    loja|\n",
            "|10000620200810|    100006|2020-08-10T00:00:...|   7498680|          9|         carne|     2275.32|      1|    loja|\n",
            "|10000620200810|    100006|2020-08-10T00:00:...|   7502256|          9|         carne|      795.54|      1|    loja|\n",
            "|10000620200810|    100006|2020-08-10T00:00:...|   2320992|          9|         carne|       49.93|      2|    loja|\n",
            "|10000720200217|    100007|2020-02-17T00:00:...|   6253644|         20|cartao credito|         478|      1|    loja|\n",
            "|10000720200217|    100007|2020-02-17T00:00:...|   5313408|         20|cartao credito|      1357.2|      1|    loja|\n",
            "|10000720200625|    100007|2020-06-25T00:00:...|   6858780|          7|cartao credito|       317.8|      1|    site|\n",
            "|10000720200217|    100007|2020-02-17T00:00:...|   6253140|         20|cartao credito|         372|      1|    loja|\n",
            "|10000820200712|    100008|2020-07-12T00:00:...|   7677504|         14|cartao credito|     1399.86|      1|    loja|\n",
            "|10000920200612|    100009|2020-06-12T00:00:...|   7571508|         20|cartao credito|        1299|      1|    loja|\n",
            "|10000920191209|    100009|2019-12-09T00:00:...|   7318728|         15|cartao credito|         999|      1|    loja|\n",
            "+--------------+----------+--------------------+----------+-----------+--------------+------------+-------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPtIsaaoMWVZ"
      },
      "source": [
        " #### Dataframe Final\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHZ6BZ9mMgeV",
        "outputId": "5ff262b9-b9b7-45da-ab10-4cb4cfe662b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pyspark.sql.functions as spark\n",
        "\n",
        "cliente = df_cliente.select(spark.col('cliente_id'))\n",
        "\n",
        "idade = df_cliente.select(spark.col('cliente_id'), (spark.year(spark.current_date()) - spark.year('dt_nascimento')).alias('idade'))                                                     \n",
        "\n",
        "recencia = df_venda \\\n",
        "  .select(spark.col('cliente_id'), spark.col('dt_pedido').cast('timestamp')) \\\n",
        "  .withColumn('recencia', spark.round(spark.months_between(spark.current_date(), 'dt_pedido').cast(\"integer\"))) \\\n",
        "  .groupBy('cliente_id') \\\n",
        "  .max('recencia') \\\n",
        "  .select(spark.col('cliente_id'), spark.col('max(recencia)').alias(\"recencia\"))\n",
        "\n",
        "qt_total_compras = df_venda \\\n",
        "  .select(spark.col('cliente_id'), spark.col('pedido_id')) \\\n",
        "  .distinct() \\\n",
        "  .groupBy('cliente_id') \\\n",
        "  .count() \\\n",
        "  .select(spark.col('cliente_id'), spark.col('count').alias(\"qt_total_compras\")) \n",
        "\n",
        "vr_total_compras = df_venda \\\n",
        "  .select(\n",
        "      spark.col('cliente_id'),\n",
        "      spark.col('vr_unit_item').cast('numeric(10,2)'),\n",
        "      spark.col('qt_item').cast('integer')) \\\n",
        "  .withColumn('vr_total_items', \n",
        "              spark.col('vr_unit_item').cast('numeric(10,2)') * \\\n",
        "              spark.col('qt_item').cast('integer')) \\\n",
        "  .groupBy('cliente_id') \\\n",
        "  .sum('vr_total_items') \\\n",
        "  .select(spark.col('cliente_id'), spark.col('sum(vr_total_items)').alias(\"vr_total_compras\")) \n",
        "\n",
        "qt_total_itens = df_venda \\\n",
        "  .select(spark.col('cliente_id'), spark.col('produto_id')) \\\n",
        "  .distinct() \\\n",
        "  .groupBy('cliente_id') \\\n",
        "  .count() \\\n",
        "  .select(spark.col('cliente_id'), spark.col('count').alias(\"qt_total_itens\"))   \n",
        "\n",
        "qt_max_parcelas = df_venda \\\n",
        "  .select(spark.col('cliente_id'), spark.col('qt_parcelas').cast('integer')) \\\n",
        "  .distinct() \\\n",
        "  .groupBy('cliente_id') \\\n",
        "  .max('qt_parcelas') \\\n",
        "  .select(spark.col('cliente_id'), spark.col('max(qt_parcelas)').alias(\"qt_max_parcelas\"))  \n",
        "\n",
        "cliente_tpc = df_venda \\\n",
        "  .select(spark.col('tp_canal'), spark.col('cliente_id')) \\\n",
        "  .distinct() \\\n",
        "  .groupBy('cliente_id') \\\n",
        "  .agg(spark.max(\"tp_canal\").alias(\"tp_canal\"))\n",
        "\n",
        "cliente_qtc = df_venda \\\n",
        "  .select(spark.col('tp_canal'), spark.col('cliente_id')) \\\n",
        "  .distinct() \\\n",
        "  .groupBy('cliente_id') \\\n",
        "  .count() \\\n",
        "  .select(spark.col('cliente_id'), spark.col('count').alias(\"qt_canal\"))     \n",
        "  \n",
        "perfil_cliente = perfil_cliente_nome.join(perfil_cliente_qt, 'cliente_id') \\\n",
        "  .withColumn('perfil_cliente', spark.when(spark.col('qt_canal') == 1, spark.col('tp_canal'))\n",
        "  .otherwise(\"multicanal\"))\n",
        "\n",
        "perfil_cliente = perfil_cliente.select(spark.col('cliente_id'),spark.col('perfil_cliente'))\n",
        "\n",
        "output = cliente.join(idade, 'cliente_id') \\\n",
        "  .join(recencia, 'cliente_id') \\\n",
        "  .join(qt_total_compras, 'cliente_id') \\\n",
        "  .join(vr_total_compras, 'cliente_id') \\\n",
        "  .join(qt_total_itens, 'cliente_id') \\\n",
        "  .join(qt_max_parcelas, 'cliente_id') \\\n",
        "  .join(perfil_cliente, 'cliente_id') \n",
        "\n",
        "output.orderBy('cliente_id').show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+--------+----------------+----------------+--------------+---------------+--------------+\n",
            "|cliente_id|idade|recencia|qt_total_compras|vr_total_compras|qt_total_itens|qt_max_parcelas|perfil_cliente|\n",
            "+----------+-----+--------+----------------+----------------+--------------+---------------+--------------+\n",
            "|    100001|   11|       4|               1|         1399.04|             1|             16|          loja|\n",
            "|    100002|   46|       8|               1|         1280.07|             1|              9|          loja|\n",
            "|    100003|   39|       3|               2|         1904.95|             3|             10|          loja|\n",
            "|    100004|   52|       9|               2|         6860.08|             2|             24|    multicanal|\n",
            "|    100005|   38|       9|               2|         3207.28|             2|             15|          loja|\n",
            "|    100006|   72|       2|               1|         3170.72|             3|              9|          loja|\n",
            "|    100007|   44|       8|               2|         2525.00|             4|             20|    multicanal|\n",
            "|    100008|   40|       3|               1|         1399.86|             1|             14|          loja|\n",
            "|    100009|   39|      10|               3|         4478.00|             4|             20|          loja|\n",
            "|    100010|   36|       9|               1|          898.97|             1|              9|          loja|\n",
            "|    100011|   43|       8|               1|         1324.80|             2|              9|          loja|\n",
            "|    100012|   46|       7|               1|         1099.98|             1|             14|          loja|\n",
            "|    100013|   56|      10|               4|         7053.58|             7|             15|    multicanal|\n",
            "|    100014|   56|       7|               2|         1746.01|             3|             11|          loja|\n",
            "|    100015|   74|       4|               2|         2592.99|             3|              9|          loja|\n",
            "|    100016|   48|       8|               1|          181.08|             2|              9|          loja|\n",
            "|    100017|   38|      10|               1|         4176.88|             2|             17|          loja|\n",
            "|    100018|   37|      10|               1|         1437.96|             3|             13|          loja|\n",
            "|    100019|   49|       7|               3|         6114.96|             3|             13|          loja|\n",
            "|    100020|   31|       3|               1|          755.66|             2|             11|          loja|\n",
            "+----------+-----+--------+----------------+----------------+--------------+---------------+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}